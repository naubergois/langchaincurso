{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 26. Engenharia de Prompt para Agentes: O Padrão ReAct\n",
                "\n",
                "Neste notebook, vamos mergulhar no coração dos Agentes de IA: o padrão **ReAct (Reasoning + Acting)**. Ao invés de usar frameworks prontos imediatamente, vamos construir um loop ReAct \"na unha\" para entender exatamente como a engenharia de prompt guia o modelo.\n",
                "\n",
                "**Objetivos:**\n",
                "1. Entender a evolução: Zero-shot -> Chain of Thought (CoT) -> ReAct.\n",
                "2. Analisar a estrutura de um Prompt ReAct.\n",
                "3. Implementar um loop de Agente Manual em Python puro.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q langchain langchain-openai openai google-search-results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import getpass\n",
                "\n",
                "if \"OPENAI_API_KEY\" not in os.environ:\n",
                "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Teoria: De Pensamento à Ação\n",
                "\n",
                "### O Problema do LLM Isolado\n",
                "LLMs são ótimos em prever texto, mas ruins em:\n",
                "1. Conhecimento atualizado (corte de treino).\n",
                "2. Matemática precisa.\n",
                "3. Interagir com o mundo real.\n",
                "\n",
                "### A Solução ReAct (Yao et al., 2022)\n",
                "O paper *ReAct: Synergizing Reasoning and Acting in Language Models* propôs um formato de prompt onde o modelo gera intercaladamente:\n",
                "- **Thought (Pensamento):** Raciocínio sobre o estado atual.\n",
                "- **Action (Ação):** Um comando específico para uma ferramenta externa.\n",
                "- **Observation (Observação):** O resultado real da ferramenta (inserido pelo código, não gerado pelo LLM)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Anatomia de um Prompt ReAct\n",
                "\n",
                "Um prompt ReAct clássico precisa de:\n",
                "1. **Instrução de Ferramentas:** Quais ferramentas existem e como usá-las.\n",
                "2. **Formato de Saída:** Instruções rígidas sobre como escrever `Thought`, `Action`, `Action Input`.\n",
                "3. **Exemplos (Few-Shot):** Demonstrations de como resolver problemas passo-a-passo. É aqui que a mágica da engenharia de prompt acontece.\n",
                "\n",
                "Vamos definir nosso prompt manual:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "REACT_PROMPT_TEMPLATE = \"\"\"\n",
                "Responda as seguintes questões o melhor que puder. Você tem acesso às seguintes ferramentas:\n",
                "\n",
                "{tool_descriptions}\n",
                "\n",
                "Use o seguinte formato:\n",
                "\n",
                "Questão: a questão de entrada que você deve responder\n",
                "Thought: você deve sempre pensar sobre o que fazer\n",
                "Action: a ação a ser tomada, deve ser uma de [{tool_names}]\n",
                "Action Input: a entrada para a ação\n",
                "Observation: o resultado da ação\n",
                "... (esse padrão Thought/Action/Action Input/Observation pode se repetir N vezes)\n",
                "Thought: agora eu sei a resposta final\n",
                "Final Answer: a resposta final para a questão original\n",
                "\n",
                "Comece!\n",
                "\n",
                "Questão: {input}\n",
                "Thought:\"\"\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Implementadando Ferramentas (Simuladas)\n",
                "\n",
                "Para este exercício, vamos criar ferramentas simples em Python."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def search_wikipedia(query):\n",
                "    \"\"\"Simula uma busca na Wikipedia (retorna um resumo fixo para teste).\"\"\"\n",
                "    print(f\"[TOOL] Buscando na Wikipedia por: {query}\")\n",
                "    # Simulação de retorno\n",
                "    if \"População do Brasil\" in query:\n",
                "        return \"A população do Brasil em 2023 era estimada em 203 milhões de pessoas.\"\n",
                "    if \"PIB do Brasil\" in query:\n",
                "        return \"O PIB do Brasil em 2023 foi de aproximadamente 2.17 trilhões de dólares.\"\n",
                "    return \"Sem resultados relevantes.\"\n",
                "\n",
                "def calculator(expression):\n",
                "    \"\"\"Calcula expressões matemáticas simples.\"\"\"\n",
                "    print(f\"[TOOL] Calculando: {expression}\")\n",
                "    try:\n",
                "        return str(eval(expression))\n",
                "    except:\n",
                "        return \"Erro no cálculo\"\n",
                "\n",
                "tools = {\n",
                "    \"Wikipedia\": search_wikipedia,\n",
                "    \"Calculator\": calculator\n",
                "}\n",
                "\n",
                "tool_names = list(tools.keys())\n",
                "tool_descriptions = \"\"\"\\n\".join([f\"{name}: {func.__doc__}\" for name, func in tools.items()])\n",
                "\n",
                "print(\"Ferramentas Disponíveis:\")\n",
                "print(tool_descriptions)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. O Loop ReAct Manual\n",
                "\n",
                "Agora vamos implementar o loop que:\n",
                "1. Chama o LLM com o histórico atual.\n",
                "2. Detecta se o LLM quer executar uma Ação (Regex).\n",
                "3. Se sim, executa a ação e anexa o resultado (`Observation`).\n",
                "4. Se não (ou se for `Final Answer`), termina."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "import re\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
                "\n",
                "def run_agent_step(prompt_so_far, max_steps=5):\n",
                "    step = 0\n",
                "    while step < max_steps:\n",
                "        # 1. Chamar o LLM\n",
                "        response = llm.invoke(prompt_so_far).content\n",
                "        prompt_so_far += response # Adiciona a resposta do LLM ao histórico\n",
                "        \n",
                "        print(f\"\\n--- Passo {step+1} LLM Output ---\\n{response}\")\n",
                "        \n",
                "        # 2. Verificar se terminou\n",
                "        if \"Final Answer:\" in response:\n",
                "            return response.split(\"Final Answer:\")[-1].strip()\n",
                "        \n",
                "        # 3. Parsear Ação com Regex\n",
                "        # Procuramos por: Action: Nome\\nAction Input: Entrada\n",
                "        action_match = re.search(r\"Action: (.*?)(\\n)*Action Input: (.*)\", response)\n",
                "        \n",
                "        if action_match:\n",
                "            action_name = action_match.group(1).strip()\n",
                "            action_input = action_match.group(3).strip()\n",
                "            \n",
                "            observation = f\"Erro: Ferramenta {action_name} não encontrada.\"\n",
                "            \n",
                "            if action_name in tools:\n",
                "                observation = tools[action_name](action_input)\n",
                "            \n",
                "            observation_str = f\"\\nObservation: {observation}\\nThought:\"\n",
                "            prompt_so_far += observation_str\n",
                "            print(f\"--- Execução Ferramenta ---\\n{observation_str}\")\n",
                "            \n",
                "        else:\n",
                "            # Se o LLM não seguiu o formato, tentamos forçar ou paramos\n",
                "            print(\"Agente não gerou uma ação válida. Encerrando.\")\n",
                "            break\n",
                "            \n",
                "        step += 1\n",
                "    \n",
                "    return \"Limite de passos atingido sem resposta final.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Teste 1: Pergunta que exige Tool\n",
                "question = \"Qual é a população do Brasil dividida por 2?\"\n",
                "\n",
                "final_prompt = REACT_PROMPT_TEMPLATE.format(\n",
                "    tool_descriptions=tool_descriptions,\n",
                "    tool_names=tool_names,\n",
                "    input=question\n",
                ")\n",
                "\n",
                "result = run_agent_step(final_prompt)\n",
                "print(f\"\\n>>> Resposta Final: {result}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Análise do Prompting\n",
                "\n",
                "Perceba que a \"inteligência\" do agente vem inteiramente do Prompt:\n",
                "1. **Thought:** O modelo \"fala consigo mesmo\" para planejar.\n",
                "2. **Stop Sequences:** Embora injeções manuais funcionem, frameworks otimizam isso parando a geração assim que veem `Observation:`.\n",
                "\n",
                "No próximo notebook, veremos como o LangChain abstrai essa complexidade, mas usa EXATAMENTE a mesma lógica por baixo dos panos."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}