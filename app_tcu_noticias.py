"""
Aplica√ß√£o principal para extra√ß√£o e an√°lise de not√≠cias do TCU.
Gera relat√≥rios executivos usando LangChain e Pydantic.
"""
import argparse
import json
import os
from datetime import datetime
from dotenv import load_dotenv

from tcu_scraper import TCUScraper
from tcu_analyzer import TCUAnalyzer
from tcu_models import RelatorioExecutivo

# Carregar vari√°veis de ambiente
load_dotenv()


def salvar_json(dados, arquivo: str):
    """Salva dados em arquivo JSON."""
    with open(arquivo, 'w', encoding='utf-8') as f:
        json.dump(dados, f, ensure_ascii=False, indent=2, default=str)
    print(f"üíæ Dados salvos em: {arquivo}")


def gerar_relatorio_markdown(relatorio: RelatorioExecutivo, arquivo: str):
    """Gera relat√≥rio executivo em formato Markdown."""
    
    md = f"""# Relat√≥rio Executivo - Not√≠cias TCU

**Per√≠odo:** {relatorio.periodo}  
**Total de Not√≠cias:** {relatorio.total_noticias}  
**Data de Gera√ß√£o:** {relatorio.data_geracao}

---

## üìä Estat√≠sticas

### Distribui√ß√£o por Categoria
"""
    
    for categoria, count in sorted(relatorio.distribuicao_categorias.items(), key=lambda x: x[1], reverse=True):
        md += f"- **{categoria}**: {count} not√≠cia(s)\n"
    
    md += "\n### Distribui√ß√£o por Relev√¢ncia\n"
    for relevancia, count in sorted(relatorio.distribuicao_relevancia.items(), key=lambda x: x[1], reverse=True):
        emoji = "üî¥" if relevancia == "Alta" else "üü°" if relevancia == "M√©dia" else "üü¢"
        md += f"- {emoji} **{relevancia}**: {count} not√≠cia(s)\n"
    
    md += f"\n---\n\n## üéØ Principais Temas\n\n"
    for i, tema in enumerate(relatorio.principais_temas, 1):
        md += f"{i}. {tema}\n"
    
    if relatorio.principais_entidades:
        md += f"\n## üè¢ Entidades Mais Mencionadas\n\n"
        for i, entidade in enumerate(relatorio.principais_entidades, 1):
            md += f"{i}. {entidade}\n"
    
    if relatorio.noticias_alta_relevancia:
        md += f"\n---\n\n## üî¥ Not√≠cias de Alta Relev√¢ncia\n\n"
        for i, noticia in enumerate(relatorio.noticias_alta_relevancia, 1):
            md += f"### {i}. {noticia['titulo']}\n\n"
            md += f"**Categoria:** {noticia['categoria']}  \n"
            md += f"**Resumo:** {noticia['resumo']}  \n"
            md += f"**Link:** [{noticia['url']}]({noticia['url']})\n\n"
    
    md += f"\n---\n\n## üí° Insights Principais\n\n"
    for i, insight in enumerate(relatorio.insights_principais, 1):
        md += f"{i}. {insight}\n"
    
    md += f"\n---\n\n## üìù Resumo Geral\n\n{relatorio.resumo_geral}\n"
    
    md += f"\n---\n\n*Relat√≥rio gerado automaticamente usando LangChain e Google Gemini*\n"
    
    with open(arquivo, 'w', encoding='utf-8') as f:
        f.write(md)
    
    print(f"üìÑ Relat√≥rio salvo em: {arquivo}")


def main():
    """Fun√ß√£o principal."""
    parser = argparse.ArgumentParser(
        description="Extrai not√≠cias do portal TCU e gera relat√≥rio executivo"
    )
    parser.add_argument(
        '-q', '--quantidade',
        type=int,
        default=5,
        help='Quantidade de not√≠cias a extrair (padr√£o: 5)'
    )
    parser.add_argument(
        '-o', '--output',
        type=str,
        default='relatorio_tcu',
        help='Nome base dos arquivos de sa√≠da (padr√£o: relatorio_tcu)'
    )
    parser.add_argument(
        '--no-analise',
        action='store_true',
        help='Apenas extrair not√≠cias sem an√°lise por IA'
    )
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("üèõÔ∏è  SISTEMA DE AN√ÅLISE DE NOT√çCIAS DO TCU")
    print("=" * 70)
    print()
    
    # Verificar API Key
    if not os.getenv("GOOGLE_API_KEY") and not args.no_analise:
        print("‚ùå GOOGLE_API_KEY n√£o configurada!")
        print("Configure a vari√°vel de ambiente ou use --no-analise")
        return
    
    # 1. Extrair not√≠cias
    scraper = TCUScraper(delay=1.0)
    noticias = scraper.extrair_noticias_completas(quantidade=args.quantidade)
    
    if not noticias:
        print("‚ùå Nenhuma not√≠cia foi extra√≠da. Verifique a conex√£o ou o site.")
        return
    
    # Salvar not√≠cias em JSON
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    arquivo_noticias = f"{args.output}_noticias_{timestamp}.json"
    
    noticias_dict = [n.dict() for n in noticias]
    salvar_json(noticias_dict, arquivo_noticias)
    
    if args.no_analise:
        print("\n‚úÖ Extra√ß√£o conclu√≠da! (an√°lise desabilitada)")
        return
    
    # 2. Analisar not√≠cias com IA
    analyzer = TCUAnalyzer()
    noticias_analisadas = analyzer.analisar_noticias(noticias)
    
    if not noticias_analisadas:
        print("‚ùå Nenhuma not√≠cia foi analisada.")
        return
    
    # Salvar an√°lises em JSON
    arquivo_analises = f"{args.output}_analises_{timestamp}.json"
    analises_dict = [n.dict() for n in noticias_analisadas]
    salvar_json(analises_dict, arquivo_analises)
    
    # 3. Gerar relat√≥rio executivo
    relatorio = analyzer.gerar_relatorio_executivo(noticias_analisadas)
    
    # Salvar relat√≥rio em JSON
    arquivo_relatorio_json = f"{args.output}_relatorio_{timestamp}.json"
    salvar_json(relatorio.dict(), arquivo_relatorio_json)
    
    # Salvar relat√≥rio em Markdown
    arquivo_relatorio_md = f"{args.output}_relatorio_{timestamp}.md"
    gerar_relatorio_markdown(relatorio, arquivo_relatorio_md)
    
    print("\n" + "=" * 70)
    print("‚úÖ PROCESSO CONCLU√çDO COM SUCESSO!")
    print("=" * 70)
    print(f"\nüìÅ Arquivos gerados:")
    print(f"  - {arquivo_noticias}")
    print(f"  - {arquivo_analises}")
    print(f"  - {arquivo_relatorio_json}")
    print(f"  - {arquivo_relatorio_md}")
    print()
    print(f"üìä Resumo:")
    print(f"  - {relatorio.total_noticias} not√≠cias analisadas")
    print(f"  - {len(relatorio.noticias_alta_relevancia)} de alta relev√¢ncia")
    print(f"  - {len(relatorio.principais_temas)} temas principais identificados")
    print()


if __name__ == "__main__":
    main()
