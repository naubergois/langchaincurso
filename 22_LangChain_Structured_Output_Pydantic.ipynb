{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22. Saída Estruturada com LangChain e Pydantic\n",
    "\n",
    "Agora vamos instruir o LLM a retornar dados validade pelo Pydantic, garantindo confiabilidade para automações.\n",
    "\n",
    "**Objetivo:** Usar `.with_structured_output()` para extrair informações complexas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854107e6",
   "metadata": {},
   "source": [
    "# Explicação Detalhada do Assunto\n",
    "\n",
    "# 22. Saída Estruturada com LangChain e Pydantic\n",
    "\n",
    "Este notebook explora como instruir modelos de linguagem (LLMs) a retornarem dados formatados e validados usando Pydantic, uma biblioteca Python para validação de dados. O objetivo é garantir a confiabilidade e a consistência dos dados gerados, tornando-os adequados para automações e integrações com outros sistemas.\n",
    "\n",
    "**Resumo Executivo:**\n",
    "\n",
    "Em cenários onde a precisão e a estrutura dos dados são cruciais, como na extração de informações para sistemas de CRM ou na criação de agentes automatizados, a capacidade de obter saídas estruturadas de LLMs é fundamental. Este notebook demonstra como usar a LangChain e o Pydantic para alcançar esse objetivo, transformando texto não estruturado em dados validados e prontos para uso.\n",
    "\n",
    "**Conceitos Chave:**\n",
    "\n",
    "*   **LLMs (Large Language Models):** Modelos de linguagem de grande escala, capazes de gerar texto, traduzir idiomas e responder a perguntas.\n",
    "*   **Pydantic:** Uma biblioteca Python para validação e gerenciamento de dados. Define estruturas de dados (schemas) e valida os dados de acordo com esses schemas.\n",
    "*   **Function Calling:** Um recurso (disponível em algumas APIs de LLMs, como a OpenAI) que permite ao modelo retornar uma função a ser executada, juntamente com os argumentos necessários. A LangChain utiliza este mecanismo para garantir o formato da saída.\n",
    "*   **Schema:** Uma definição formal da estrutura dos dados, incluindo os tipos de dados esperados para cada campo.\n",
    "\n",
    "**Objetivos de Aprendizado:**\n",
    "\n",
    "Após completar este notebook, você será capaz de:\n",
    "\n",
    "*   Definir schemas de dados usando Pydantic.\n",
    "*   Configurar um LLM da LangChain para retornar saídas estruturadas de acordo com um schema Pydantic.\n",
    "*   Extrair informações de texto não estruturado e convertê-las em objetos Pydantic validados.\n",
    "*   Entender as vantagens de usar Pydantic para validação de dados em comparação com a análise de JSON puro.\n",
    "*   Aplicar os conceitos aprendidos para criar agentes e automações mais confiáveis.\n",
    "\n",
    "**Importância no Ecossistema LangChain:**\n",
    "\n",
    "A capacidade de obter saídas estruturadas e validadas é crucial para construir aplicações LangChain robustas e confiáveis. Sem essa validação, os dados gerados pelos LLMs podem ser inconsistentes ou incorretos, levando a erros e comportamentos inesperados. Ao integrar o Pydantic com a LangChain, podemos garantir que os dados utilizados em nossos pipelines de IA sejam precisos, consistentes e adequados para as tarefas a serem executadas. Isso é especialmente importante ao construir agentes que interagem com APIs e outros sistemas externos.\n",
    "\n",
    "## 1. Definindo o Schema\n",
    "\n",
    "Imagine que queremos extrair informações de um currículo...\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:00.214368Z",
     "iopub.status.busy": "2026-02-02T02:36:00.212527Z",
     "iopub.status.idle": "2026-02-02T02:36:00.252136Z",
     "shell.execute_reply": "2026-02-02T02:36:00.251254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### INJECTION START ###\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "    os.environ['OPENAI_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "### INJECTION END ###\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# !pip install -qU langchain langchain-openai langchain-community pydantic # Script-patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:00.256193Z",
     "iopub.status.busy": "2026-02-02T02:36:00.255949Z",
     "iopub.status.idle": "2026-02-02T02:36:00.263251Z",
     "shell.execute_reply": "2026-02-02T02:36:00.261476Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "except ImportError:\n",
    "    userdata = None\n",
    "import getpass\n",
    "\n",
    "try:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "except:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definindo o Schema\n",
    "\n",
    "Imagine que queremos extrair informações de um currículo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:00.267257Z",
     "iopub.status.busy": "2026-02-02T02:36:00.266843Z",
     "iopub.status.idle": "2026-02-02T02:36:00.339471Z",
     "shell.execute_reply": "2026-02-02T02:36:00.338621Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Experiencia(BaseModel):\n",
    "    cargo: str = Field(description=\"Cargo ocupado\")\n",
    "    empresa: str = Field(description=\"Nome da empresa\")\n",
    "    anos: int = Field(description=\"Duração em anos (arredondado)\")\n",
    "\n",
    "class Curriculo(BaseModel):\n",
    "    nome: str = Field(description=\"Nome do candidato\")\n",
    "    skills: List[str] = Field(description=\"Lista de habilidades técnicas\")\n",
    "    historico: List[Experiencia]\n",
    "    resumo_perfil: str = Field(description=\"Resumo do perfil em 1 frase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurando o LLM\n",
    "\n",
    "O método `.with_structured_output` usa Function Calling por baixo dos panos (na OpenAI) para garantir o formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:00.342098Z",
     "iopub.status.busy": "2026-02-02T02:36:00.341888Z",
     "iopub.status.idle": "2026-02-02T02:36:01.391154Z",
     "shell.execute_reply": "2026-02-02T02:36:01.390498Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.9.6). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/auth/__init__.py:54: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/oauth2/__init__.py:40: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:47: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  from google.generativeai.caching import CachedContent  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "\n",
    "structured_llm = llm.with_structured_output(Curriculo)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um recrutador especialista. Extraia os dados do currículo fornecido.\"),\n",
    "    (\"human\", \"{cv_text}\")\n",
    "])\n",
    "\n",
    "extractor = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extraindo Dados\n",
    "\n",
    "Vamos passar um texto não estruturado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:01.394829Z",
     "iopub.status.busy": "2026-02-02T02:36:01.394245Z",
     "iopub.status.idle": "2026-02-02T02:36:03.419599Z",
     "shell.execute_reply": "2026-02-02T02:36:03.418814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidata: Ana Souza\n",
      "Skills: ['Python', 'SQL', 'Docker']\n",
      " - Desenvolvedora Python na TechCorp (5 anos)\n",
      " - Estagiária de Java na BancoDev (1 anos)\n"
     ]
    }
   ],
   "source": [
    "texto_cv = \"\"\"\n",
    "Me chamo Ana Souza. Sou desenvolvedora Python há 5 anos, tendo trabalhado na TechCorp. \n",
    "Antes disso, fui estagiária de Java na BancoDev por 1 ano. \n",
    "Sei muito de SQL e Docker também.\n",
    "\"\"\"\n",
    "\n",
    "resultado = extractor.invoke({\"cv_text\": texto_cv})\n",
    "\n",
    "print(f\"Candidata: {resultado.nome}\")\n",
    "print(f\"Skills: {resultado.skills}\")\n",
    "for exp in resultado.historico:\n",
    "    print(f\" - {exp.cargo} na {exp.empresa} ({exp.anos} anos)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Por que isso é melhor que JSON puro no prompt?\n",
    "\n",
    "1. **Validação**: Se o LLM alucinar um campo obrigatório faltando, o Pydantic avisa.\n",
    "2. **Tipagem**: `anos` vem como `int`, não `string`.\n",
    "3. **Facilidade**: O objeto retornado já é uma classe Python, com autocompletar no IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Essa é a base para criar Agentes Confiáveis. Se o agente precisa chamar uma API que exige `int`, o Pydantic garante que ele não vai enviar `\"dez\"` por escrito."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
