{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:38.412432Z",
     "iopub.status.busy": "2026-02-03T11:17:38.412343Z",
     "iopub.status.idle": "2026-02-03T11:17:39.302076Z",
     "shell.execute_reply": "2026-02-03T11:17:39.299489Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instalação do pymongo para registro de exceções\n",
    "# !pip install pymongo # Script-patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:39.308683Z",
     "iopub.status.busy": "2026-02-03T11:17:39.308361Z",
     "iopub.status.idle": "2026-02-03T11:17:39.910043Z",
     "shell.execute_reply": "2026-02-03T11:17:39.909665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Handler global para capturar exceções e salvar no MongoDB\n",
    "import sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Configuração do MongoDB (ajuste o URI conforme necessário)\n",
    "MONGO_URI = \"mongodb://localhost:27017\"\n",
    "DB_NAME = \"notebooks\"\n",
    "COLLECTION_NAME = \"exceptions\"\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "collection = db[COLLECTION_NAME]\n",
    "\n",
    "def excecao_para_mongo(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "    tb_str = ''.join(traceback.format_exception(exc_type, exc_value, exc_traceback))\n",
    "    doc = {\n",
    "        \"timestamp\": datetime.utcnow(),\n",
    "        \"type\": str(exc_type),\n",
    "        \"value\": str(exc_value),\n",
    "        \"traceback\": tb_str,\n",
    "        \"notebook\": \"06_RAG_Embeddings_VectorStores.ipynb\"\n",
    "    }\n",
    "    collection.insert_one(doc)\n",
    "    print(f\"Exceção registrada no MongoDB: {exc_type} - {exc_value}\")\n",
    "\n",
    "sys.excepthook = excecao_para_mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:39.912004Z",
     "iopub.status.busy": "2026-02-03T11:17:39.911889Z",
     "iopub.status.idle": "2026-02-03T11:17:39.913411Z",
     "shell.execute_reply": "2026-02-03T11:17:39.913140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instalação dos pacotes necessários para Colab\n",
    "# !pip install python-dotenv langchain langchain-community langchain-text-splitters langchain-google-genai faiss-cpu bs4 # Script-patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:39.914539Z",
     "iopub.status.busy": "2026-02-03T11:17:39.914457Z",
     "iopub.status.idle": "2026-02-03T11:17:39.915992Z",
     "shell.execute_reply": "2026-02-03T11:17:39.915766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuração da chave de API do Google Generative AI\\nimport os\\nfrom dotenv import load_dotenv\\nimport sys\\n# Carrega .env do local ou de pastas comuns\\nfor p in ['.', '..', 'scripts', '../scripts']:\\n    path = os.path.join(p, '.env')\\n    if os.path.exists(path):\\n        load_dotenv(path)\\n        break\\nif os.getenv('GOOGLE_API_KEY'):\\n    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. RAG Parte 2: Embeddings e Vector Stores\n",
    "\n",
    "Com os textos divididos, precisamos transformá-los em números (vetores) para que possamos fazer busca semântica (por significado, não por palavra-chave exata).\n",
    "\n",
    "**Objetivos:**\n",
    "- Entender o que são Embeddings.\n",
    "- Criar um Vector Store (FAISS) para armazenar os vetores.\n",
    "- Fazer uma busca de similaridade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feff9d1",
   "metadata": {},
   "source": [
    "# Explicação Detalhada do Assunto\n",
    "\n",
    "# 06. RAG Parte 2: Embeddings e Vector Stores\n",
    "\n",
    "Bem-vindo ao segundo notebook da nossa jornada em Retrieval Augmented Generation (RAG)! Neste notebook, mergulharemos no coração do RAG, explorando como transformar texto bruto em representações numéricas significativas, que possibilitam a busca semântica eficiente. Preparar-se para dar vida aos seus dados!\n",
    "\n",
    "## Resumo Executivo\n",
    "\n",
    "Este notebook demonstra o processo essencial de criação de um \"banco de dados\" de conhecimento vetorial. Partindo de textos divididos em chunks, aprenderemos como usar embeddings para representá-los como vetores e, em seguida, como indexá-los em um Vector Store (FAISS) para realizar buscas de similaridade semântica. O objetivo final é construir uma base sólida para o nosso sistema RAG, permitindo que ele encontre informações relevantes com base no significado, e não apenas em palavras-chave.\n",
    "\n",
    "## Conceitos Chave\n",
    "\n",
    "Para entender completamente o que faremos, vamos revisar alguns conceitos importantes:\n",
    "\n",
    "*   **Embeddings:** Um modelo de embedding converte texto em um vetor de números (uma lista de floats, por exemplo). Esse vetor representa o significado semântico do texto, permitindo que textos com significados semelhantes tenham vetores próximos no espaço vetorial.\n",
    "*   **Vector Store:** Um banco de dados especializado para armazenar e indexar vetores (embeddings). Ele permite buscas rápidas e eficientes por vetores similares, o que é crucial para encontrar os chunks de texto mais relevantes para uma determinada consulta. FAISS (Facebook AI Similarity Search) é uma biblioteca popular para construir Vector Stores.\n",
    "*   **Busca de Similaridade:** O processo de encontrar os vetores mais próximos (mais similares) a um determinado vetor de consulta dentro de um Vector Store. Isso nos permite encontrar os chunks de texto que são semanticamente mais relacionados à pergunta do usuário.\n",
    "\n",
    "## Objetivos de Aprendizado\n",
    "\n",
    "Ao concluir este notebook, você será capaz de:\n",
    "\n",
    "*   Transformar documentos de texto em embeddings usando um modelo como o `GoogleGenerativeAIEmbeddings`.\n",
    "*   Criar um Vector Store (usando FAISS) para indexar seus embeddings.\n",
    "*   Realizar buscas de similaridade em seu Vector Store para encontrar chunks de texto relevantes.\n",
    "*   Entender o papel fundamental dos embeddings e Vector Stores na arquitetura RAG.\n",
    "\n",
    "## Importância no Ecossistema LangChain\n",
    "\n",
    "Este notebook é crucial porque estabelece a base para a funcionalidade de busca do nosso sistema RAG. A capacidade de encontrar informações relevantes de forma eficiente é o que permite ao LLM gerar respostas informativas e contextualmente apropriadas. Sem embeddings e Vector Stores, estaríamos limitados à busca por palavras-chave, o que frequentemente resulta em resultados irrelevantes ou incompletos. Ao dominar essas técnicas, você estará preparado para construir sistemas RAG poderosos e eficazes com LangChain.\n",
    "\n",
    "Vamos começar a transformar texto em conhecimento acionável!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:39.917177Z",
     "iopub.status.busy": "2026-02-03T11:17:39.917093Z",
     "iopub.status.idle": "2026-02-03T11:17:39.957192Z",
     "shell.execute_reply": "2026-02-03T11:17:39.956944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### INJECTION START ###\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "# Carrega .env do local ou de pastas comuns\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "### INJECTION END ###\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "# Autenticação automática do script\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# !pip install -qU langchain langchain-openai langchain-community faiss-cpu python-dotenv # Script-patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:39.989746Z",
     "iopub.status.busy": "2026-02-03T11:17:39.989623Z",
     "iopub.status.idle": "2026-02-03T11:17:39.991784Z",
     "shell.execute_reply": "2026-02-03T11:17:39.991526Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "except ImportError:\n",
    "    userdata = None\n",
    "import getpass\n",
    "\n",
    "try:\n",
    "    pass # Script-patched: using env var\n",
    "except:\n",
    "    pass # Script-patched: using env var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prep: Recriando os Chunks\n",
    "\n",
    "Vamos repetir rapidamente o passo anterior para ter os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:39.992870Z",
     "iopub.status.busy": "2026-02-03T11:17:39.992782Z",
     "iopub.status.idle": "2026-02-03T11:17:42.296912Z",
     "shell.execute_reply": "2026-02-03T11:17:42.296419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Carregando docs pequenos para exemplo\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(urls)\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embeddings\n",
    "\n",
    "Modelo de Embedding converte texto em um vetor de números (ex: lista de 1536 floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:42.299146Z",
     "iopub.status.busy": "2026-02-03T11:17:42.299024Z",
     "iopub.status.idle": "2026-02-03T11:17:43.252844Z",
     "shell.execute_reply": "2026-02-03T11:17:43.252555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.9.6). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/auth/__init__.py:54: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/oauth2/__init__.py:40: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:47: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  from google.generativeai.caching import CachedContent  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Substitua 'SUA_CHAVE_API' pela sua chave do Google Generative AI\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=os.getenv(\"GOOGLE_API_KEY\", \"SUA_CHAVE_API\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vector Store (FAISS)\n",
    "\n",
    "O FAISS (Facebook AI Similarity Search) é uma biblioteca eficiente para busca de similaridade. Vamos indexar nossos chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:43.254279Z",
     "iopub.status.busy": "2026-02-03T11:17:43.254131Z",
     "iopub.status.idle": "2026-02-03T11:17:46.021008Z",
     "shell.execute_reply": "2026-02-03T11:17:46.020285Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Cria o índice vetorial\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "# Podemos consultar o índice\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2}) # k=2 retorna os 2 mais similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Busca de Similaridade\n",
    "\n",
    "Vamos ver se ele encontra trechos relevantes sobre \"Tool use\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:17:46.026212Z",
     "iopub.status.busy": "2026-02-03T11:17:46.025640Z",
     "iopub.status.idle": "2026-02-03T11:17:56.807427Z",
     "shell.execute_reply": "2026-02-03T11:17:56.803131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CONTEÚDO (len=637) ---\n",
      "LLM Powered Autonomous Agents | Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table o...\n",
      "\n",
      "\n",
      "--- CONTEÚDO (len=947) ---\n",
      "The generative agent architecture. (Image source: Park et al. 2023)\n",
      "\n",
      "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many ot...\n",
      "\n",
      "\n",
      "--- CONTEÚDO (len=50) ---\n",
      "Overview of a LLM-powered autonomous agent system....\n",
      "\n",
      "\n",
      "--- CONTEÚDO (len=666) ---\n",
      "Component Three: Tool Use\n",
      "\n",
      "Case Studies\n",
      "\n",
      "Scientific Discovery Agent\n",
      "\n",
      "Generative Agents Simulation\n",
      "\n",
      "Proof-of-Concept Examples\n",
      "\n",
      "\n",
      "Challenges\n",
      "\n",
      "Citation\n",
      "\n",
      "References\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as Auto...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = vectorstore.similarity_search(\"What are autonomous agents?\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"--- CONTEÚDO (len={len(doc.page_content)}) ---\")\n",
    "    print(doc.page_content[:300] + \"...\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Criamos nosso \"banco de dados\" de conhecimento vetorial.\n",
    "\n",
    "No próximo notebook, vamos juntar tudo: pegar a pergunta do usuário, buscar no FAISS, e passar para o LLM responder (RAG completo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
