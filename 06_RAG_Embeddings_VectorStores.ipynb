{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. RAG Parte 2: Embeddings e Vector Stores\n",
    "\n",
    "Com os textos divididos, precisamos transformá-los em números (vetores) para que possamos fazer busca semântica (por significado, não por palavra-chave exata).\n",
    "\n",
    "**Objetivos:**\n",
    "- Entender o que são Embeddings.\n",
    "- Criar um Vector Store (FAISS) para armazenar os vetores.\n",
    "- Fazer uma busca de similaridade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feff9d1",
   "metadata": {},
   "source": [
    "# Explicação Detalhada do Assunto\n",
    "\n",
    "# 06. RAG Parte 2: Embeddings e Vector Stores\n",
    "\n",
    "Bem-vindo ao segundo notebook da nossa jornada em Retrieval Augmented Generation (RAG)! Neste notebook, mergulharemos no coração do RAG, explorando como transformar texto bruto em representações numéricas significativas, que possibilitam a busca semântica eficiente. Preparar-se para dar vida aos seus dados!\n",
    "\n",
    "## Resumo Executivo\n",
    "\n",
    "Este notebook demonstra o processo essencial de criação de um \"banco de dados\" de conhecimento vetorial. Partindo de textos divididos em chunks, aprenderemos como usar embeddings para representá-los como vetores e, em seguida, como indexá-los em um Vector Store (FAISS) para realizar buscas de similaridade semântica. O objetivo final é construir uma base sólida para o nosso sistema RAG, permitindo que ele encontre informações relevantes com base no significado, e não apenas em palavras-chave.\n",
    "\n",
    "## Conceitos Chave\n",
    "\n",
    "Para entender completamente o que faremos, vamos revisar alguns conceitos importantes:\n",
    "\n",
    "*   **Embeddings:** Um modelo de embedding converte texto em um vetor de números (uma lista de floats, por exemplo). Esse vetor representa o significado semântico do texto, permitindo que textos com significados semelhantes tenham vetores próximos no espaço vetorial.\n",
    "*   **Vector Store:** Um banco de dados especializado para armazenar e indexar vetores (embeddings). Ele permite buscas rápidas e eficientes por vetores similares, o que é crucial para encontrar os chunks de texto mais relevantes para uma determinada consulta. FAISS (Facebook AI Similarity Search) é uma biblioteca popular para construir Vector Stores.\n",
    "*   **Busca de Similaridade:** O processo de encontrar os vetores mais próximos (mais similares) a um determinado vetor de consulta dentro de um Vector Store. Isso nos permite encontrar os chunks de texto que são semanticamente mais relacionados à pergunta do usuário.\n",
    "\n",
    "## Objetivos de Aprendizado\n",
    "\n",
    "Ao concluir este notebook, você será capaz de:\n",
    "\n",
    "*   Transformar documentos de texto em embeddings usando um modelo como o `GoogleGenerativeAIEmbeddings`.\n",
    "*   Criar um Vector Store (usando FAISS) para indexar seus embeddings.\n",
    "*   Realizar buscas de similaridade em seu Vector Store para encontrar chunks de texto relevantes.\n",
    "*   Entender o papel fundamental dos embeddings e Vector Stores na arquitetura RAG.\n",
    "\n",
    "## Importância no Ecossistema LangChain\n",
    "\n",
    "Este notebook é crucial porque estabelece a base para a funcionalidade de busca do nosso sistema RAG. A capacidade de encontrar informações relevantes de forma eficiente é o que permite ao LLM gerar respostas informativas e contextualmente apropriadas. Sem embeddings e Vector Stores, estaríamos limitados à busca por palavras-chave, o que frequentemente resulta em resultados irrelevantes ou incompletos. Ao dominar essas técnicas, você estará preparado para construir sistemas RAG poderosos e eficazes com LangChain.\n",
    "\n",
    "Vamos começar a transformar texto em conhecimento acionável!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:58.307794Z",
     "iopub.status.busy": "2026-02-02T02:34:58.307467Z",
     "iopub.status.idle": "2026-02-02T02:34:58.324743Z",
     "shell.execute_reply": "2026-02-02T02:34:58.324278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### INJECTION START ###\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "# Carrega .env do local ou de pastas comuns\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "### INJECTION END ###\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "# Autenticação automática do script\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# !pip install -qU langchain langchain-openai langchain-community faiss-cpu python-dotenv # Script-patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:58.326626Z",
     "iopub.status.busy": "2026-02-02T02:34:58.326477Z",
     "iopub.status.idle": "2026-02-02T02:34:58.329177Z",
     "shell.execute_reply": "2026-02-02T02:34:58.328842Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "except ImportError:\n",
    "    userdata = None\n",
    "import getpass\n",
    "\n",
    "try:\n",
    "    pass # Script-patched: using env var\n",
    "except:\n",
    "    pass # Script-patched: using env var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prep: Recriando os Chunks\n",
    "\n",
    "Vamos repetir rapidamente o passo anterior para ter os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:58.330532Z",
     "iopub.status.busy": "2026-02-02T02:34:58.330411Z",
     "iopub.status.idle": "2026-02-02T02:34:58.659636Z",
     "shell.execute_reply": "2026-02-02T02:34:58.659317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Carregando docs pequenos para exemplo\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(urls)\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embeddings\n",
    "\n",
    "Modelo de Embedding converte texto em um vetor de números (ex: lista de 1536 floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:58.661200Z",
     "iopub.status.busy": "2026-02-02T02:34:58.661106Z",
     "iopub.status.idle": "2026-02-02T02:34:59.162201Z",
     "shell.execute_reply": "2026-02-02T02:34:59.161924Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.9.6). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/auth/__init__.py:54: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/oauth2/__init__.py:40: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:47: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  from google.generativeai.caching import CachedContent  # type: ignore[import]\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for GoogleGenerativeAIEmbeddings\nmodel\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleGenerativeAIEmbeddings\n\u001b[0;32m----> 3\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mGoogleGenerativeAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pydantic/main.py:250\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    249\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    252\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    256\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    257\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for GoogleGenerativeAIEmbeddings\nmodel\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vector Store (FAISS)\n",
    "\n",
    "O FAISS (Facebook AI Similarity Search) é uma biblioteca eficiente para busca de similaridade. Vamos indexar nossos chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:59.163462Z",
     "iopub.status.busy": "2026-02-02T02:34:59.163372Z",
     "iopub.status.idle": "2026-02-02T02:34:59.225386Z",
     "shell.execute_reply": "2026-02-02T02:34:59.225155Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Cria o índice vetorial\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(documents\u001b[38;5;241m=\u001b[39msplits, embedding\u001b[38;5;241m=\u001b[39m\u001b[43membeddings\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Podemos consultar o índice\u001b[39;00m\n\u001b[1;32m      7\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m}) \u001b[38;5;66;03m# k=2 retorna os 2 mais similares\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Cria o índice vetorial\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "# Podemos consultar o índice\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2}) # k=2 retorna os 2 mais similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Busca de Similaridade\n",
    "\n",
    "Vamos ver se ele encontra trechos relevantes sobre \"Tool use\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:59.226590Z",
     "iopub.status.busy": "2026-02-02T02:34:59.226511Z",
     "iopub.status.idle": "2026-02-02T02:34:59.233455Z",
     "shell.execute_reply": "2026-02-02T02:34:59.233216Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are autonomous agents?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- CONTEÚDO (len=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(doc\u001b[38;5;241m.\u001b[39mpage_content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "docs = vectorstore.similarity_search(\"What are autonomous agents?\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"--- CONTEÚDO (len={len(doc.page_content)}) ---\")\n",
    "    print(doc.page_content[:300] + \"...\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Criamos nosso \"banco de dados\" de conhecimento vetorial.\n",
    "\n",
    "No próximo notebook, vamos juntar tudo: pegar a pergunta do usuário, buscar no FAISS, e passar para o LLM responder (RAG completo)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
