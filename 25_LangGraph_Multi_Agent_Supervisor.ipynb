{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25. LangGraph: Multi-Agent Supervisor\n",
    "\n",
    "O padrão mais avançado de agentes é ter múltiplos especialistas (ex: um Pesquisador, um Codificador, um Revisor) orquestrados por um Supervisor.\n",
    "\n",
    "**Objetivos:**\n",
    "- Criar agentes especialistas.\n",
    "- Criar um nó Supervisor que decide quem chamar.\n",
    "- Criar o grafo de roteamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34677d03",
   "metadata": {},
   "source": [
    "# Explicação Detalhada do Assunto\n",
    "\n",
    "# 25. LangGraph: Supervisor Multi-Agente\n",
    "\n",
    "Este notebook explora um dos padrões mais avançados na construção de agentes inteligentes: a orquestração de múltiplos agentes especialistas sob a supervisão de um agente coordenador. Imagine ter uma equipe de especialistas, cada um com habilidades únicas (como pesquisa, redação e revisão), trabalhando em conjunto para resolver um problema complexo. Este notebook demonstra como construir essa equipe e como o Supervisor direciona o fluxo de trabalho para alcançar o objetivo final.\n",
    "\n",
    "**Conceitos Chave:**\n",
    "\n",
    "*   **Agentes Especialistas:** Módulos de código (neste caso, chains simples) projetados para realizar tarefas específicas, como pesquisa na web ou redação de textos.\n",
    "*   **Supervisor:** Um agente central que toma decisões sobre qual agente especialista deve ser ativado em seguida, com base no progresso da tarefa e nas informações disponíveis. Ele atua como um maestro, garantindo que cada membro da equipe contribua no momento certo.\n",
    "*   **LangGraph:** Uma ferramenta poderosa do LangChain que permite definir fluxos de trabalho complexos como grafos. Isso facilita a criação de pipelines de agentes interconectados e a gestão do estado da aplicação.\n",
    "*   **Estado:** A informação compartilhada entre os agentes, contendo dados como a tarefa original, os resultados da pesquisa e o texto final em desenvolvimento. O estado é atualizado a cada iteração do grafo.\n",
    "\n",
    "**Objetivos de Aprendizado:**\n",
    "\n",
    "Ao concluir este notebook, você será capaz de:\n",
    "\n",
    "*   Definir agentes especialistas com funções específicas.\n",
    "*   Implementar um supervisor capaz de tomar decisões sobre o fluxo de trabalho.\n",
    "*   Construir um grafo LangGraph para orquestrar a interação entre os agentes e o supervisor.\n",
    "*   Executar o grafo e observar como os agentes colaboram para completar uma tarefa complexa.\n",
    "*   Compreender a importância da gestão de estado em aplicações multi-agente.\n",
    "\n",
    "**Importância no Ecossistema LangChain:**\n",
    "\n",
    "A capacidade de construir sistemas multi-agente é fundamental para resolver problemas complexos que exigem especialização e colaboração. Este notebook demonstra um padrão avançado que permite criar aplicações de IA mais robustas, flexíveis e adaptáveis. Dominar este padrão é um passo importante para se tornar um especialista em LangChain e IA Generativa. A orquestração de agentes é crucial para tarefas como:\n",
    "\n",
    "*   **Criação de conteúdo complexo:** Geração de artigos, relatórios e apresentações que exigem pesquisa, redação e revisão.\n",
    "*   **Resolução de problemas técnicos:** Diagnóstico de falhas, desenvolvimento de soluções e implementação de código.\n",
    "*   **Automação de processos de negócios:** Coordenação de diferentes etapas em um fluxo de trabalho, envolvendo múltiplos atores e sistemas.\n",
    "\n",
    "Prepare-se para mergulhar no mundo dos agentes inteligentes e descobrir como o LangGraph pode te ajudar a construir aplicações de IA de última geração!\n",
    "\n",
    "## 1. Definindo os Agentes Especialistas\n",
    "\n",
    "Para simplificar, usaremos chains simples como \"agentes\".\n",
    "\n",
    "## 2. O Supervisor\n",
    "\n",
    "Ele decide qual o próximo passo. Usamos `with_structured_output` para forçar ele a escolher um dos agentes ou FINISH.\n",
    "\n",
    "## 3. Montando o Grafo\n",
    "\n",
    "Estado e roteamento.\n",
    "\n",
    "## 4. Executando o Time\n",
    "\n",
    "Vamos pedir para escrever sobre Python.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:15.475052Z",
     "iopub.status.busy": "2026-02-02T02:36:15.474740Z",
     "iopub.status.idle": "2026-02-02T02:36:15.489390Z",
     "shell.execute_reply": "2026-02-02T02:36:15.487632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### INJECTION START ###\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "    os.environ['OPENAI_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "### INJECTION END ###\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# !pip install -qU langchain langchain-openai langchain-community langgraph # Script-patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:15.499270Z",
     "iopub.status.busy": "2026-02-02T02:36:15.499008Z",
     "iopub.status.idle": "2026-02-02T02:36:15.504198Z",
     "shell.execute_reply": "2026-02-02T02:36:15.503166Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "except ImportError:\n",
    "    userdata = None\n",
    "import getpass\n",
    "\n",
    "try:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "except:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definindo os Agentes Especialistas\n",
    "\n",
    "Para simplificar, usaremos chains simples como \"agentes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:15.508253Z",
     "iopub.status.busy": "2026-02-02T02:36:15.507845Z",
     "iopub.status.idle": "2026-02-02T02:36:16.916199Z",
     "shell.execute_reply": "2026-02-02T02:36:16.913173Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.9.6). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/auth/__init__.py:54: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/oauth2/__init__.py:40: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:47: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  from google.generativeai.caching import CachedContent  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "def agente_pesquisador(state):\n",
    "    print(\"--- PESQUISADOR ATUANDO ---\")\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Você é um pesquisador web. Retorne dados factuais sobre o tema.\"),\n",
    "        HumanMessage(content=state['tarefa'])\n",
    "    ]\n",
    "    res = llm.invoke(messages)\n",
    "    return {\"resultado_pesquisa\": res.content, \"ultimo_agente\": \"pesquisador\"}\n",
    "\n",
    "def agente_redator(state):\n",
    "    print(\"--- REDATOR ATUANDO ---\")\n",
    "    pesquisa = state.get('resultado_pesquisa', 'Sem dados')\n",
    "    messages = [\n",
    "        SystemMessage(content=\"Você é um redator. Escreva um parágrafo elegante baseada na pesquisa.\"),\n",
    "        HumanMessage(content=f\"Tarefa original: {state['tarefa']}. Pesquisa: {pesquisa}\")\n",
    "    ]\n",
    "    res = llm.invoke(messages)\n",
    "    return {\"texto_final\": res.content, \"ultimo_agente\": \"redator\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. O Supervisor\n",
    "\n",
    "Ele decide qual o próximo passo. Usamos `with_structured_output` para forçar ele a escolher um dos agentes ou FINISH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:16.943179Z",
     "iopub.status.busy": "2026-02-02T02:36:16.938384Z",
     "iopub.status.idle": "2026-02-02T02:36:16.990919Z",
     "shell.execute_reply": "2026-02-02T02:36:16.966517Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class DecisaoSupervisor(BaseModel):\n",
    "    proximo: Literal[\"pesquisador\", \"redator\", \"FINISH\"]\n",
    "\n",
    "supervisor_llm = llm.with_structured_output(DecisaoSupervisor)\n",
    "\n",
    "def supervisor(state):\n",
    "    print(\"--- SUPERVISOR PENSANDO ---\")\n",
    "    prompt = f\"\"\"\n",
    "    Tarefa: {state['tarefa']}\n",
    "    Último agente: {state.get('ultimo_agente')}\n",
    "    \n",
    "    Se não tiver pesquisa, chame o 'pesquisador'.\n",
    "    Se já tiver pesquisa, chame o 'redator'.\n",
    "    Se já tiver texto final ('ultimo_agente' for redator), chame 'FINISH'.\n",
    "    \"\"\"\n",
    "    decisao = supervisor_llm.invoke(prompt)\n",
    "    return {\"proximo_passo\": decisao.proximo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Montando o Grafo\n",
    "\n",
    "Estado e roteamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:17.011113Z",
     "iopub.status.busy": "2026-02-02T02:36:17.010260Z",
     "iopub.status.idle": "2026-02-02T02:36:17.076429Z",
     "shell.execute_reply": "2026-02-02T02:36:17.075316Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class TeamState(TypedDict):\n",
    "    tarefa: str\n",
    "    resultado_pesquisa: Optional[str]\n",
    "    texto_final: Optional[str]\n",
    "    ultimo_agente: Optional[str]\n",
    "    proximo_passo: str\n",
    "\n",
    "workflow = StateGraph(TeamState)\n",
    "\n",
    "workflow.add_node(\"supervisor\", supervisor)\n",
    "workflow.add_node(\"pesquisador\", agente_pesquisador)\n",
    "workflow.add_node(\"redator\", agente_redator)\n",
    "\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Arestas normais: depois dos trabalhadores, volta pro supervisor decidir\n",
    "workflow.add_edge(\"pesquisador\", \"supervisor\")\n",
    "workflow.add_edge(\"redator\", \"supervisor\")\n",
    "\n",
    "# Aresta condicional saindo do supervisor\n",
    "def roteador_supervisor(state):\n",
    "    if state['proximo_passo'] == \"FINISH\":\n",
    "        return END\n",
    "    return state['proximo_passo']\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    roteador_supervisor,\n",
    "    {\n",
    "        \"pesquisador\": \"pesquisador\",\n",
    "        \"redator\": \"redator\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Executando o Time\n",
    "\n",
    "Vamos pedir para escrever sobre Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:17.080398Z",
     "iopub.status.busy": "2026-02-02T02:36:17.080157Z",
     "iopub.status.idle": "2026-02-02T02:36:26.764654Z",
     "shell.execute_reply": "2026-02-02T02:36:26.762858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUPERVISOR PENSANDO ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PESQUISADOR ATUANDO ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUPERVISOR PENSANDO ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- REDATOR ATUANDO ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUPERVISOR PENSANDO ---\n"
     ]
    }
   ],
   "source": [
    "res = app.invoke({\"tarefa\": \"Escreva um resumo histórico sobre a linguagem Python.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:36:26.772994Z",
     "iopub.status.busy": "2026-02-02T02:36:26.772321Z",
     "iopub.status.idle": "2026-02-02T02:36:26.777947Z",
     "shell.execute_reply": "2026-02-02T02:36:26.777299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEXTO FINAL ===\n",
      "No final da década de 1980, Guido van Rossum concebeu o Python no CWI, nos Países Baixos, como um sucessor do ABC, influenciado pelo SETL. O Python foi lançado pela primeira vez em 1991 (versão 0.9.0) e passou por grandes evoluções com as versões 1.0 (1994), que introduziu ferramentas de programação funcional, e 2.0 (2000), que apresentou a compreensão de lista e a recolha de lixo. A versão 3.0 (2008) procurou corrigir falhas intrínsecas, levando ao fim do suporte para a 2.7 em 2020. O Python, uma linguagem de programação de alto nível e de propósito geral, enfatiza a legibilidade do código através de indentação significativa, tipagem dinâmica e recolha de lixo. A sua versatilidade reside no suporte a múltiplos paradigmas e numa vasta biblioteca padrão, o que a torna adequada para desenvolvimento web, ciência de dados e IA. A sua natureza gratuita e de código aberto, a compatibilidade entre plataformas e a comunidade de apoio contribuem para a sua popularidade entre os programadores.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TEXTO FINAL ===\")\n",
    "print(res['texto_final'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Criamos uma arquitetura hierárquica onde um Supervisor gerencia o fluxo entre subordinados. Este é o estado da arte em sistemas baseados em Agentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
