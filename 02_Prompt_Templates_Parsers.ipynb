{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Prompt Templates e Output Parsers\n",
    "\n",
    "Agora que sabemos chamar os modelos, precisamos estruturar melhor nossos prompts e processar as respostas. Usaremos **Prompt Templates** e **Output Parsers**, e introduziremos a sintaxe LCEL (LangChain Expression Language).\n",
    "\n",
    "**Objetivos:**\n",
    "- Criar templates de prompt dinâmicos.\n",
    "- Usar parsers para limpar a saída.\n",
    "- Criar nossa primeira Chain usando o operador `|`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153b234",
   "metadata": {},
   "source": [
    "# Explicação Detalhada do Assunto\n",
    "\n",
    "# 02. Prompt Templates e Output Parsers\n",
    "\n",
    "Bem-vindo ao segundo notebook da nossa jornada LangChain! Agora que já aprendemos a interagir com modelos de linguagem, é hora de aprimorar a forma como estruturamos nossas solicitações (prompts) e como processamos as respostas geradas. Neste notebook, vamos explorar dois conceitos cruciais: **Prompt Templates** e **Output Parsers**.\n",
    "\n",
    "## Resumo Executivo\n",
    "\n",
    "Este notebook é um guia prático para dominar a arte de criar prompts eficazes e de extrair informações valiosas das respostas dos modelos de linguagem. Através de exemplos claros e concisos, você aprenderá a utilizar `Prompt Templates` para organizar e reutilizar seus prompts, e `Output Parsers` para formatar as respostas dos modelos de acordo com suas necessidades.\n",
    "\n",
    "## Conceitos Chave\n",
    "\n",
    "*   **Prompt Templates**: São modelos que permitem definir a estrutura de um prompt, incluindo variáveis que podem ser preenchidas dinamicamente. Em vez de construir prompts manualmente concatenando strings, você usará templates para criar prompts mais organizados, legíveis e reutilizáveis.\n",
    "*   **Output Parsers**: São ferramentas que permitem processar e formatar as respostas dos modelos de linguagem. Eles extraem o conteúdo relevante da resposta, convertem-no para o formato desejado (por exemplo, string, lista, JSON) e garantem que as informações sejam apresentadas de forma consistente.\n",
    "*   **LCEL (LangChain Expression Language)**: É a linguagem de expressão do LangChain que permite conectar diferentes componentes (como Prompt Templates, modelos de linguagem e Output Parsers) em um fluxo de trabalho coeso, utilizando o operador \"pipe\" (`|`).\n",
    "\n",
    "## Objetivos de Aprendizado\n",
    "\n",
    "Ao concluir este notebook, você será capaz de:\n",
    "\n",
    "*   Criar e utilizar `Prompt Templates` para estruturar seus prompts de forma eficiente.\n",
    "*   Aplicar `Output Parsers` para extrair e formatar as respostas dos modelos de linguagem.\n",
    "*   Construir `Chains` utilizando a `LangChain Expression Language (LCEL)` para conectar diferentes componentes em um fluxo de trabalho.\n",
    "*   Desenvolver aplicações práticas que utilizam prompts dinâmicos e processamento de saída.\n",
    "\n",
    "## Importância no Ecossistema LangChain\n",
    "\n",
    "Dominar `Prompt Templates` e `Output Parsers` é fundamental para construir aplicações LangChain robustas e escaláveis. Eles permitem que você:\n",
    "\n",
    "*   **Otimize a interação com os modelos de linguagem**: Prompts bem estruturados levam a respostas mais precisas e relevantes.\n",
    "*   **Automatize o processamento de informações**: Extrair e formatar as respostas dos modelos de forma consistente economiza tempo e evita erros.\n",
    "*   **Crie fluxos de trabalho complexos**: Conectar diferentes componentes com a LCEL permite construir aplicações sofisticadas que resolvem problemas reais.\n",
    "\n",
    "Prepare-se para elevar suas habilidades LangChain a um novo patamar! Vamos começar a explorar o poder dos Prompt Templates e Output Parsers.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:29.949927Z",
     "iopub.status.busy": "2026-02-02T02:34:29.949434Z",
     "iopub.status.idle": "2026-02-02T02:34:29.969183Z",
     "shell.execute_reply": "2026-02-02T02:34:29.968784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### INJECTION START ###\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "# Carrega .env do local ou de pastas comuns\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "### INJECTION END ###\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "# Autenticação automática do script\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "# Look for .env in scripts folder\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# !pip install -qU langchain langchain-openai langchain-community python-dotenv # Script-patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:29.971006Z",
     "iopub.status.busy": "2026-02-02T02:34:29.970871Z",
     "iopub.status.idle": "2026-02-02T02:34:29.973589Z",
     "shell.execute_reply": "2026-02-02T02:34:29.973297Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "except ImportError:\n",
    "    userdata = None\n",
    "import getpass\n",
    "\n",
    "try:\n",
    "    pass # Script-patched\n",
    "except:\n",
    "    pass # Script-patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:29.974985Z",
     "iopub.status.busy": "2026-02-02T02:34:29.974852Z",
     "iopub.status.idle": "2026-02-02T02:34:30.744717Z",
     "shell.execute_reply": "2026-02-02T02:34:30.744376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.9.6). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/auth/__init__.py:54: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/oauth2/__init__.py:40: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:47: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  from google.generativeai.caching import CachedContent  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prompt Templates\n",
    "\n",
    "Em vez de concatenar strings manualmente (`\"Traduza \" + texto + \" para inglês\"`), usamos `PromptTemplate`. Isso ajuda a organizar variáveis e permite reutilização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:30.746412Z",
     "iopub.status.busy": "2026-02-02T02:34:30.746263Z",
     "iopub.status.idle": "2026-02-02T02:34:30.779455Z",
     "shell.execute_reply": "2026-02-02T02:34:30.779181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='Você é um tradutor profissional. Traduza o texto a seguir para Francês.', additional_kwargs={}, response_metadata={}), HumanMessage(content='O gato está na mesa.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Criando um template a partir de mensagens\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um tradutor profissional. Traduza o texto a seguir para {idioma}.\"),\n",
    "    (\"user\", \"{texto}\")\n",
    "])\n",
    "\n",
    "# Podemos ver como fica o prompt formatado\n",
    "prompt_val = prompt_template.invoke({\"idioma\": \"Francês\", \"texto\": \"O gato está na mesa.\"})\n",
    "print(prompt_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Output Parsers\n",
    "\n",
    "A resposta do modelo é um objeto `AIMessage`. Frequentemente queremos apenas o texto (string). O `StrOutputParser` extrai o conteúdo da mensagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:30.780748Z",
     "iopub.status.busy": "2026-02-02T02:34:30.780603Z",
     "iopub.status.idle": "2026-02-02T02:34:30.783679Z",
     "shell.execute_reply": "2026-02-02T02:34:30.783392Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LCEL: LangChain Expression Language\n",
    "\n",
    "É aqui que a mágica acontece. O LangChain moderno usa o operador \"pipe\" (`|`) para conectar componentes.\n",
    "\n",
    "Fluxo: `Prompt -> Modelo -> Parser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:30.784888Z",
     "iopub.status.busy": "2026-02-02T02:34:30.784806Z",
     "iopub.status.idle": "2026-02-02T02:34:32.295318Z",
     "shell.execute_reply": "2026-02-02T02:34:32.294607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me gusta programar en Python.\n"
     ]
    }
   ],
   "source": [
    "# Criando a chain\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "# Executando a chain\n",
    "# Passamos um dicionário com as variáveis definidas no prompt_template\n",
    "resultado = chain.invoke({\"idioma\": \"Espanhol\", \"texto\": \"Eu gosto de programar em Python.\"})\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exemplo Prático: Gerador de Nomes de Empresas\n",
    "\n",
    "Vamos criar uma chain que sugere nomes de empresas com base em um produto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T02:34:32.299320Z",
     "iopub.status.busy": "2026-02-02T02:34:32.298753Z",
     "iopub.status.idle": "2026-02-02T02:34:35.227034Z",
     "shell.execute_reply": "2026-02-02T02:34:35.226592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com certeza! Aqui estão 3 sugestões de nomes criativos para uma empresa que fabrica tênis de corrida feitos de material reciclado, com um breve explicação do raciocínio por trás de cada um:\n",
      "\n",
      "1.  **EcoStride:**\n",
      "    *   Combina \"Eco\" (ecológico) com \"Stride\" (passada, ritmo), transmitindo a ideia de corrida sustentável. É um nome curto, fácil de lembrar e que comunica diretamente o foco da empresa em sustentabilidade e desempenho na corrida.\n",
      "\n",
      "2.  **ReRun Athletics:**\n",
      "    *   \"ReRun\" sugere a reutilização e o ciclo de vida prolongado dos materiais reciclados. \"Athletics\" adiciona um toque de seriedade e profissionalismo, indicando que os tênis são feitos para atletas e atividades físicas.\n",
      "\n",
      "3.  **Phoenix Footwear:**\n",
      "    *   Faz alusão à lenda da Fênix, que renasce das cinzas, simbolizando a transformação de materiais reciclados em algo novo e valioso. \"Footwear\" é uma forma direta e clara de indicar o tipo de produto que a empresa oferece.\n",
      "\n",
      "Espero que estas sugestões sejam úteis! Se precisar de mais opções ou quiser explorar nomes com foco em algum aspecto específico (como o tipo de material reciclado utilizado), é só me dizer.\n"
     ]
    }
   ],
   "source": [
    "name_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um consultor de branding criativo.\"),\n",
    "    (\"user\", \"Sugira 3 nomes criativos para uma empresa que fabrica {produto}.\")\n",
    "])\n",
    "\n",
    "name_chain = name_prompt | llm | parser\n",
    "\n",
    "print(name_chain.invoke({\"produto\": \"tênis de corrida feitos de material reciclado\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Neste notebook, vimos como:\n",
    "1. Criar prompts com variáveis usando `ChatPromptTemplate`.\n",
    "2. Limpar a saída (extrair texto) usando `StrOutputParser`.\n",
    "3. Encadeá-los usando o pipe `|` (LCEL).\n",
    "\n",
    "No próximo notebook, aprenderemos a adicionar **Memória** às nossas conversas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
