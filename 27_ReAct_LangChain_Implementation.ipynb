{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 27. ReAct: A Abordagem LangChain\n",
                "\n",
                "No notebook anterior, construímos um agente \"na mão\". Agora vamos ver como o LangChain abstrai isso para facilitar a construção de sistemas complexos.\n",
                "\n",
                "**Objetivos:**\n",
                "1. Usar ferramentas pré-construídas do LangChain.\n",
                "2. Criar um Agente ReAct padrão (`create_react_agent`).\n",
                "3. **Engenharia de Prompt Reversa:** Baixar e analisar o prompt padrão do LangChain Hub para entender as boas práticas embutidas nele.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q langchain langchain-openai langchainhub google-search-results numexpr"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import getpass\n",
                "\n",
                "if \"OPENAI_API_KEY\" not in os.environ:\n",
                "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
                "    \n",
                "# Opcional: SerpAPI para busca real no Google\n",
                "# if \"SERPAPI_API_KEY\" not in os.environ:\n",
                "#     os.environ[\"SERPAPI_API_KEY\"] = getpass.getpass(\"Enter SerpAPI Key (optional): \")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Definindo Ferramentas no LangChain\n",
                "\n",
                "O LangChain facilita a criação de ferramentas robustas usando o decorador `@tool`. O docstring da função é **CRUCIAL**, pois ele é injetado no prompt para o LLM entender quando usar a ferramenta."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import tool\n",
                "\n",
                "@tool\n",
                "def get_word_length(word: str) -> int:\n",
                "    \"\"\"Retorna o tamanho (número de caracteres) de uma palavra.\"\"\"\n",
                "    return len(word)\n",
                "\n",
                "@tool\n",
                "def get_weather(city: str) -> str:\n",
                "    \"\"\"Retorna a previsão do tempo para uma cidade específica. Use para perguntas sobre clima.\"\"\"\n",
                "    # Mock para exemplo\n",
                "    return f\"O tempo em {city} está ensolarado, 25 graus.\"\n",
                "\n",
                "tools = [get_word_length, get_weather]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. O Prompt do LangChain Hub\n",
                "\n",
                "Ao invés de escrevermos o prompt template gigante (como no notebook anterior), vamos puxar o padrão da comunidade testado em batalha.\n",
                "\n",
                "O prompt `hwchase17/react` é o padrão *gold standard*."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain import hub\n",
                "\n",
                "# Baixando o prompt\n",
                "prompt = hub.pull(\"hwchase17/react\")\n",
                "\n",
                "# Vamos imprimir para estudar sua estrutura\n",
                "print(\"--- Prompt Template Padrão ---\")\n",
                "print(prompt.template)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Análise do Prompt\n",
                "\n",
                "Note que ele possui variáveis como `{tools}`, `{tool_names}` e `{agent_scratchpad}`.\n",
                "\n",
                "- **{tools}**: Descrições das ferramentas (automático).\n",
                "- **{tool_names}**: Lista de nomes (automático).\n",
                "- **{agent_scratchpad}**: Onde o histórico de Pensamento/Ação/Observação é injetado para manter o contexto."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Criando o Agente (Agent Construction)\n",
                "\n",
                "Vamos usar `create_react_agent`. O \"Executor\" é quem roda o loop (o equivalente ao nosso `run_agent_step` manual)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import AgentExecutor, create_react_agent\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
                "\n",
                "# Criação do Agente (a \"mente\" que decide o que fazer baseada no prompt)\n",
                "agent = create_react_agent(llm, tools, prompt)\n",
                "\n",
                "# Criação do Executor (o \"corpo\" que executa as ações e loops)\n",
                "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
                "\n",
                "# handle_parsing_errors=True é uma técnica de engenharia de prompt automática!\n",
                "# Se o LLM falhar no formato, o LangChain injeta uma instrução de erro no prompt pedindo para corrigir."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Rodando o Agente\n",
                "\n",
                "Vamos ver o `verbose=True` em ação, mostrando o pensamento."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"Quantas letras tem a palavra 'paralelepípedo' e como está o tempo no Rio de Janeiro?\"\n",
                "\n",
                "response = agent_executor.invoke({\"input\": query})\n",
                "\n",
                "print(f\"\\nResposta: {response['output']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Exercício Prático: Modificando o Prompt Base\n",
                "\n",
                "E se quisermos que o agente sempre responda como um pirata?\n",
                "Podemos injetar instruções no topo do prompt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modificando o template manualmente\n",
                "prompt.template = \"VOCÊ É UM PIRATA REBULIÇO! SEMPRE RESPONDA COMO TAL.\\n\\n\" + prompt.template\n",
                "\n",
                "agent_pirata = create_react_agent(llm, tools, prompt)\n",
                "executor_pirata = AgentExecutor(agent=agent_pirata, tools=tools, verbose=True)\n",
                "\n",
                "executor_pirata.invoke({\"input\": \"Como está o tempo em São Paulo?\"})"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}