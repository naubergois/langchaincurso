{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27. ReAct: A Abordagem LangChain\n",
    "\n",
    "No notebook anterior, construímos um agente \"na mão\". Agora vamos ver como o LangChain abstrai isso para facilitar a construção de sistemas complexos.\n",
    "\n",
    "**Objetivos:**\n",
    "1. Usar ferramentas pré-construídas do LangChain.\n",
    "2. Criar um Agente ReAct padrão (`create_react_agent`).\n",
    "3. **Engenharia de Prompt Reversa:** Baixar e analisar o prompt padrão do LangChain Hub para entender as boas práticas embutidas nele.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2238b3b",
   "metadata": {},
   "source": [
    "# Explicação Detalhada do Assunto\n",
    "\n",
    "# 27. ReAct: A Abordagem LangChain\n",
    "\n",
    "Bem-vindo! Neste notebook, vamos mergulhar na implementação do padrão ReAct (Reasoning and Acting) utilizando o LangChain. Se você construiu um agente \"na mão\" no notebook anterior, prepare-se para ver como o LangChain simplifica drasticamente o processo, permitindo a criação de sistemas complexos com muito mais facilidade.\n",
    "\n",
    "**Resumo Executivo:**\n",
    "\n",
    "Este notebook demonstra como utilizar o LangChain para construir um agente ReAct eficaz. Exploraremos a definição de ferramentas, a utilização de prompts pré-definidos do LangChain Hub e a criação e execução do agente. O foco é mostrar como o LangChain abstrai a complexidade da construção de agentes, tornando o processo mais acessível e eficiente.\n",
    "\n",
    "**Conceitos Chave:**\n",
    "\n",
    "*   **ReAct (Reasoning and Acting):** Um padrão para agentes de IA que combina raciocínio (reasoning) para gerar planos e ações (acting) para interagir com o ambiente.\n",
    "*   **LangChain Hub:** Um repositório de prompts, chains e agentes pré-construídos e testados pela comunidade, que podem ser facilmente reutilizados.\n",
    "*   **Ferramentas (Tools):** Funções específicas que o agente pode utilizar para interagir com o mundo externo, como buscar informações na internet ou calcular o tamanho de uma palavra.\n",
    "*   **`@tool` Decorator:** Uma funcionalidade do LangChain que simplifica a criação de ferramentas, injetando automaticamente a documentação da função no prompt do agente.\n",
    "*   **AgentExecutor:** O componente do LangChain responsável por executar o loop de raciocínio e ação do agente.\n",
    "\n",
    "**Objetivos de Aprendizado:**\n",
    "\n",
    "Ao concluir este notebook, você será capaz de:\n",
    "\n",
    "*   Definir e integrar ferramentas personalizadas em um agente LangChain utilizando o decorador `@tool`.\n",
    "*   Utilizar prompts pré-definidos do LangChain Hub para acelerar o desenvolvimento de agentes.\n",
    "*   Construir um agente ReAct completo utilizando as funcionalidades do LangChain.\n",
    "*   Compreender o fluxo de execução de um agente LangChain, incluindo o raciocínio, a seleção de ferramentas e a interação com o ambiente.\n",
    "*   Interpretar o output detalhado (verbose) do agente para entender seu processo de tomada de decisão.\n",
    "\n",
    "**Importância no Ecossistema LangChain:**\n",
    "\n",
    "O padrão ReAct é fundamental para a construção de agentes inteligentes e capazes de resolver problemas complexos. O LangChain fornece as ferramentas e abstrações necessárias para implementar o ReAct de forma eficiente, permitindo que você se concentre na lógica de negócio em vez de se preocupar com os detalhes de implementação. Dominar a construção de agentes ReAct com LangChain é um passo essencial para aproveitar ao máximo o poder da IA generativa.\n",
    "\n",
    "## 1. Definindo Ferramentas no LangChain\n",
    "\n",
    "O LangChain facilita a criação de ferramentas robustas usando o decorador `@tool`. O docstring da função é **CRUCIAL**, pois ele é injetado no prompt para o LLM saber como usar a ferramenta!\n",
    "\n",
    "## 2. O Prompt do LangChain Hub\n",
    "\n",
    "Ao invés de escrevermos o prompt template gigante (como no notebook anterior), vamos puxar o padrão da comunidade testado em batalha.\n",
    "\n",
    "O prompt `hwchase17/react` é o padrão para o ReAct.\n",
    "\n",
    "### Análise do Prompt\n",
    "\n",
    "Note que ele possui variáveis como `{tools}`, `{tool_names}` e `{agent_scratchpad}`.\n",
    "\n",
    "*   **{tools}**: Descrições das ferramentas (automático).\n",
    "*   **{tool_names}**: Lista de nomes das ferramentas (automático).\n",
    "*   **{agent\\_scratchpad}**: Histórico das interações do agente (automático).\n",
    "\n",
    "## 3. Criando o Agente (Agent Construction)\n",
    "\n",
    "Vamos usar `create_react_agent`. O \"Executor\" é quem roda o loop (o equivalente ao nosso `run_agent_step` manual).\n",
    "\n",
    "## 4. Rodando o Agente\n",
    "\n",
    "Vamos ver o `verbose=True` em ação, mostrando o pensamento.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:20:05.476041Z",
     "iopub.status.busy": "2026-02-03T11:20:05.475956Z",
     "iopub.status.idle": "2026-02-03T11:20:05.483291Z",
     "shell.execute_reply": "2026-02-03T11:20:05.483032Z"
    }
   },
   "outputs": [],
   "source": [
    "### INJECTION START ###\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "for p in ['.', '..', 'scripts', '../scripts']:\n",
    "    path = os.path.join(p, '.env')\n",
    "    if os.path.exists(path):\n",
    "        load_dotenv(path)\n",
    "        break\n",
    "if os.getenv('GOOGLE_API_KEY'):\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "    os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "### INJECTION END ###\n",
    "\n",
    "# !pip install -q langchain langchain-openai langchainhub google-search-results numexpr # Script-patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:20:05.484828Z",
     "iopub.status.busy": "2026-02-03T11:20:05.484735Z",
     "iopub.status.idle": "2026-02-03T11:20:05.486773Z",
     "shell.execute_reply": "2026-02-03T11:20:05.486511Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    \n",
    "# Opcional: SerpAPI para busca real no Google\n",
    "# if \"SERPAPI_API_KEY\" not in os.environ:\n",
    "    pass # Script-patched: ensure non-empty block\n",
    "#     os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\"): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definindo Ferramentas no LangChain\n",
    "\n",
    "O LangChain facilita a criação de ferramentas robustas usando o decorador `@tool`. O docstring da função é **CRUCIAL**, pois ele é injetado no prompt para o LLM entender quando usar a ferramenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:20:05.488170Z",
     "iopub.status.busy": "2026-02-03T11:20:05.488095Z",
     "iopub.status.idle": "2026-02-03T11:20:06.200198Z",
     "shell.execute_reply": "2026-02-03T11:20:06.199822Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Retorna o tamanho (número de caracteres) de uma palavra.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Retorna a previsão do tempo para uma cidade específica. Use para perguntas sobre clima.\"\"\"\n",
    "    # Mock para exemplo\n",
    "    return f\"O tempo em {city} está ensolarado, 25 graus.\"\n",
    "\n",
    "tools = [get_word_length, get_weather]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. O Prompt do LangChain Hub\n",
    "\n",
    "Ao invés de escrevermos o prompt template gigante (como no notebook anterior), vamos puxar o padrão da comunidade testado em batalha.\n",
    "\n",
    "O prompt `hwchase17/react` é o padrão *gold standard*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:20:06.201862Z",
     "iopub.status.busy": "2026-02-03T11:20:06.201729Z",
     "iopub.status.idle": "2026-02-03T11:20:06.570398Z",
     "shell.execute_reply": "2026-02-03T11:20:06.569971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prompt Template Padrão ---\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Baixando o prompt\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Vamos imprimir para estudar sua estrutura\n",
    "print(\"--- Prompt Template Padrão ---\")\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise do Prompt\n",
    "\n",
    "Note que ele possui variáveis como `{tools}`, `{tool_names}` e `{agent_scratchpad}`.\n",
    "\n",
    "- **{tools}**: Descrições das ferramentas (automático).\n",
    "- **{tool_names}**: Lista de nomes (automático).\n",
    "- **{agent_scratchpad}**: Onde o histórico de Pensamento/Ação/Observação é injetado para manter o contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Criando o Agente (Agent Construction)\n",
    "\n",
    "Vamos usar `create_react_agent`. O \"Executor\" é quem roda o loop (o equivalente ao nosso `run_agent_step` manual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:20:06.571941Z",
     "iopub.status.busy": "2026-02-03T11:20:06.571834Z",
     "iopub.status.idle": "2026-02-03T11:20:07.014367Z",
     "shell.execute_reply": "2026-02-03T11:20:07.014031Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.9.6). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/auth/__init__.py:54: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/google/oauth2/__init__.py:40: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/naubergois/Library/Python/3.9/lib/python/site-packages/langchain_google_genai/chat_models.py:47: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  from google.generativeai.caching import CachedContent  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "\n",
    "# Criação do Agente (a \"mente\" que decide o que fazer baseada no prompt)\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Criação do Executor (o \"corpo\" que executa as ações e loops)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# handle_parsing_errors=True é uma técnica de engenharia de prompt automática!\n",
    "# Se o LLM falhar no formato, o LangChain injeta uma instrução de erro no prompt pedindo para corrigir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rodando o Agente\n",
    "\n",
    "Vamos ver o `verbose=True` em ação, mostrando o pensamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:20:07.016036Z",
     "iopub.status.busy": "2026-02-03T11:20:07.015876Z",
     "iopub.status.idle": "2026-02-03T11:20:09.870644Z",
     "shell.execute_reply": "2026-02-03T11:20:09.870301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: The question has two parts. First, I need to find the length of the word 'paralelepípedo'. Second, I need to get the weather in Rio de Janeiro.\n",
      "Action: get_word_length\n",
      "Action Input: paralelepípedo\u001b[0m\u001b[36;1m\u001b[1;3m14\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI have the length of the word. Now I need to get the weather in Rio de Janeiro.\n",
      "Action: get_weather\n",
      "Action Input: Rio de Janeiro\u001b[0m\u001b[33;1m\u001b[1;3mO tempo em Rio de Janeiro está ensolarado, 25 graus.\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI have both answers.\n",
      "Final Answer: A palavra 'paralelepípedo' tem 14 letras e o tempo no Rio de Janeiro está ensolarado, 25 graus.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Resposta: A palavra 'paralelepípedo' tem 14 letras e o tempo no Rio de Janeiro está ensolarado, 25 graus.\n"
     ]
    }
   ],
   "source": [
    "query = \"Quantas letras tem a palavra 'paralelepípedo' e como está o tempo no Rio de Janeiro?\"\n",
    "\n",
    "response = agent_executor.invoke({\"input\": query})\n",
    "\n",
    "print(f\"\\nResposta: {response['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exercício Prático: Modificando o Prompt Base\n",
    "\n",
    "E se quisermos que o agente sempre responda como um pirata?\n",
    "Podemos injetar instruções no topo do prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T11:20:09.872134Z",
     "iopub.status.busy": "2026-02-03T11:20:09.872019Z",
     "iopub.status.idle": "2026-02-03T11:20:11.694824Z",
     "shell.execute_reply": "2026-02-03T11:20:11.694580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mArrr, um pirata precisa saber o tempo, hein? Preciso usar meu telescópio mágico para descobrir!\n",
      "\n",
      "Thought: Preciso usar a ferramenta para saber o clima em São Paulo.\n",
      "Action: get_weather\n",
      "Action Input: São Paulo\u001b[0m\u001b[33;1m\u001b[1;3mO tempo em São Paulo está ensolarado, 25 graus.\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mArrr, agora eu sei!\n",
      "\n",
      "Final Answer: Arrr, o tempo em São Paulo está ensolarado, 25 graus!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Como está o tempo em São Paulo?',\n",
       " 'output': 'Arrr, o tempo em São Paulo está ensolarado, 25 graus!'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modificando o template manualmente\n",
    "prompt.template = \"VOCÊ É UM PIRATA REBULIÇO! SEMPRE RESPONDA COMO TAL.\\n\\n\" + prompt.template\n",
    "\n",
    "agent_pirata = create_react_agent(llm, tools, prompt)\n",
    "executor_pirata = AgentExecutor(agent=agent_pirata, tools=tools, verbose=True)\n",
    "\n",
    "executor_pirata.invoke({\"input\": \"Como está o tempo em São Paulo?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
