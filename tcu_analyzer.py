"""
Analisador de not√≠cias do TCU usando LangChain e Google Gemini.
"""
import os
from typing import List
from datetime import datetime
from collections import Counter

from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

from tcu_models import (
    NoticiaCompleta,
    AnaliseNoticia,
    NoticiaAnalisada,
    RelatorioExecutivo
)


class TCUAnalyzer:
    """Analisador de not√≠cias usando LLM."""
    
    def __init__(self, model: str = "gemini-2.0-flash", temperature: float = 0):
        """
        Inicializa o analisador.
        
        Args:
            model: Nome do modelo Gemini a usar
            temperature: Temperatura para gera√ß√£o (0 = determin√≠stico)
        """
        self.llm = ChatGoogleGenerativeAI(model=model, temperature=temperature)
        self.structured_llm = self.llm.with_structured_output(AnaliseNoticia)
    
    def analisar_noticia(self, noticia: NoticiaCompleta) -> AnaliseNoticia:
        """
        Analisa uma not√≠cia e extrai informa√ß√µes estruturadas.
        
        Args:
            noticia: Not√≠cia completa a ser analisada
            
        Returns:
            AnaliseNoticia com informa√ß√µes extra√≠das
        """
        sistema = """
Voc√™ √© um especialista em an√°lise de not√≠cias do Tribunal de Contas da Uni√£o (TCU).

Analise a not√≠cia fornecida e extraia as seguintes informa√ß√µes:

1. **Categoria**: Classifique em uma das categorias principais:
   - Fiscaliza√ß√£o (auditorias, inspe√ß√µes, monitoramentos)
   - Jur√≠dico (ac√≥rd√£os, decis√µes, processos)
   - Institucional (eventos, nomea√ß√µes, comunicados)
   - Obras e Infraestrutura
   - Gest√£o P√∫blica
   - Transpar√™ncia e Controle
   - Outros

2. **Relev√¢ncia**: Avalie como Alta, M√©dia ou Baixa considerando:
   - Impacto financeiro
   - Abrang√™ncia (nacional, regional, local)
   - Interesse p√∫blico
   - Urg√™ncia

3. **Palavras-chave**: Identifique 3-5 palavras-chave principais

4. **Resumo Executivo**: Crie um resumo objetivo em 2-3 frases

5. **Impacto**: Descreva brevemente o impacto ou import√¢ncia da not√≠cia

6. **Entidades Mencionadas**: Liste √≥rg√£os, empresas ou entidades citadas
"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", sistema),
            ("human", """
T√≠tulo: {titulo}
Data: {data}
Conte√∫do: {conteudo}

Analise esta not√≠cia do TCU.
""")
        ]) | self.structured_llm
        
        resultado = prompt.invoke({
            "titulo": noticia.titulo,
            "data": noticia.data,
            "conteudo": noticia.conteudo[:3000]  # Limitar tamanho para evitar tokens excessivos
        })
        
        return resultado
    
    def analisar_noticias(self, noticias: List[NoticiaCompleta]) -> List[NoticiaAnalisada]:
        """
        Analisa m√∫ltiplas not√≠cias.
        
        Args:
            noticias: Lista de not√≠cias a analisar
            
        Returns:
            Lista de NoticiaAnalisada
        """
        noticias_analisadas = []
        
        print(f"üîç Analisando {len(noticias)} not√≠cias com IA...\n")
        
        for i, noticia in enumerate(noticias, 1):
            print(f"[{i}/{len(noticias)}] Analisando: {noticia.titulo[:60]}...")
            
            try:
                analise = self.analisar_noticia(noticia)
                
                noticia_analisada = NoticiaAnalisada(
                    noticia=noticia,
                    analise=analise
                )
                
                noticias_analisadas.append(noticia_analisada)
                print(f"  ‚úì Categoria: {analise.categoria} | Relev√¢ncia: {analise.relevancia}\n")
                
            except Exception as e:
                print(f"  ‚ùå Erro na an√°lise: {e}\n")
                continue
        
        print(f"‚úÖ {len(noticias_analisadas)} not√≠cias analisadas!\n")
        return noticias_analisadas
    
    def gerar_relatorio_executivo(
        self,
        noticias_analisadas: List[NoticiaAnalisada]
    ) -> RelatorioExecutivo:
        """
        Gera relat√≥rio executivo consolidado.
        
        Args:
            noticias_analisadas: Lista de not√≠cias analisadas
            
        Returns:
            RelatorioExecutivo
        """
        print("üìä Gerando relat√≥rio executivo...\n")
        
        # Estat√≠sticas
        categorias = [n.analise.categoria for n in noticias_analisadas]
        relevancia = [n.analise.relevancia for n in noticias_analisadas]
        
        distribuicao_categorias = dict(Counter(categorias))
        distribuicao_relevancia = dict(Counter(relevancia))
        
        # Principais temas (palavras-chave mais frequentes)
        todas_palavras = []
        for n in noticias_analisadas:
            todas_palavras.extend(n.analise.palavras_chave)
        
        principais_temas = [palavra for palavra, _ in Counter(todas_palavras).most_common(10)]
        
        # Principais entidades
        todas_entidades = []
        for n in noticias_analisadas:
            todas_entidades.extend(n.analise.entidades_mencionadas)
        
        principais_entidades = [ent for ent, _ in Counter(todas_entidades).most_common(10)]
        
        # Not√≠cias de alta relev√¢ncia
        noticias_alta = [
            {
                "titulo": n.noticia.titulo,
                "resumo": n.analise.resumo_executivo,
                "categoria": n.analise.categoria,
                "url": n.noticia.url
            }
            for n in noticias_analisadas
            if n.analise.relevancia == "Alta"
        ]
        
        # Gerar insights usando LLM
        insights = self._gerar_insights(noticias_analisadas)
        resumo_geral = self._gerar_resumo_geral(noticias_analisadas)
        
        # Per√≠odo
        if noticias_analisadas:
            datas = [n.noticia.data for n in noticias_analisadas if n.noticia.data]
            periodo = f"√öltimas {len(noticias_analisadas)} not√≠cias"
        else:
            periodo = "Sem per√≠odo definido"
        
        relatorio = RelatorioExecutivo(
            periodo=periodo,
            total_noticias=len(noticias_analisadas),
            data_geracao=datetime.now().strftime("%d/%m/%Y %H:%M"),
            distribuicao_categorias=distribuicao_categorias,
            distribuicao_relevancia=distribuicao_relevancia,
            principais_temas=principais_temas,
            principais_entidades=principais_entidades,
            noticias_alta_relevancia=noticias_alta,
            insights_principais=insights,
            resumo_geral=resumo_geral
        )
        
        print("‚úÖ Relat√≥rio executivo gerado!\n")
        return relatorio
    
    def _gerar_insights(self, noticias_analisadas: List[NoticiaAnalisada]) -> List[str]:
        """Gera insights principais usando LLM."""
        
        # Preparar contexto
        contexto = "\n\n".join([
            f"- {n.noticia.titulo} ({n.analise.categoria}, {n.analise.relevancia}): {n.analise.resumo_executivo}"
            for n in noticias_analisadas[:10]  # Limitar para evitar tokens excessivos
        ])
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um analista do TCU. Analise as not√≠cias fornecidas e identifique 
3-5 insights principais, tend√™ncias ou padr√µes importantes. Seja conciso e objetivo."""),
            ("human", "Not√≠cias:\n{contexto}\n\nQuais s√£o os principais insights?")
        ])
        
        chain = prompt | self.llm
        
        try:
            resultado = chain.invoke({"contexto": contexto})
            # Dividir em lista de insights
            insights_text = resultado.content
            insights = [line.strip("- ").strip() for line in insights_text.split("\n") if line.strip()]
            return insights[:5]
        except:
            return ["An√°lise de insights n√£o dispon√≠vel"]
    
    def _gerar_resumo_geral(self, noticias_analisadas: List[NoticiaAnalisada]) -> str:
        """Gera resumo geral do per√≠odo."""
        
        contexto = "\n\n".join([
            f"- {n.noticia.titulo}: {n.analise.resumo_executivo}"
            for n in noticias_analisadas[:10]
        ])
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um analista do TCU. Crie um resumo executivo geral 
(2-3 par√°grafos) das principais atividades e not√≠cias do per√≠odo."""),
            ("human", "Not√≠cias:\n{contexto}\n\nResumo geral:")
        ])
        
        chain = prompt | self.llm
        
        try:
            resultado = chain.invoke({"contexto": contexto})
            return resultado.content
        except:
            return "Resumo geral n√£o dispon√≠vel"
