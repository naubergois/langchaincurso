{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 28. ReAct Avançado: Ferramentas Personalizadas e Robustez\n",
                "\n",
                "A parte mais crítica da engenharia de prompt em agentes não é o prompt principal do agente (que é bem padronizado), mas sim **como descrevemos as ferramentas**.\n",
                "\n",
                "Se o LLM não entender o que a ferramenta faz ou como passar os parâmetros, ele vai alucinar ou falhar.\n",
                "\n",
                "**Objetivos:**\n",
                "1. Criar ferramentas com argumentos complexos (Pydantic).\n",
                "2. Engenharia de Prompt nas descrições das ferramentas.\n",
                "3. Lidar com erros de formatação.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q langchain langchain-openai pydantic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import getpass\n",
                "\n",
                "if \"OPENAI_API_KEY\" not in os.environ:\n",
                "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Ferramentas Estruturadas (Structured Tools)\n",
                "\n",
                "Ferramentas simples recebem uma única string. Ferramentas reais precisam de múltiplos argumentos (ex: `reservar_passagem(origem, destino, data)`).\n",
                "\n",
                "Usamos **Pydantic** para definir o schema dos argumentos. Esse schema é **convertido em texto/JSON** e inserido no prompt do LLM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.tools import StructuredTool\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "# 1. Definir o Schema de Entrada\n",
                "class CalculadoraInvestimentoInput(BaseModel):\n",
                "    valor_inicial: float = Field(description=\"O valor inicial do investimento em reais\")\n",
                "    anos: int = Field(description=\"Duração do investimento em anos\")\n",
                "    risco: str = Field(description=\"Perfil de risco: 'baixo', 'medio' ou 'alto'\")\n",
                "\n",
                "# 2. Definir a Função\n",
                "def simular_investimento(valor_inicial: float, anos: int, risco: str) -> str:\n",
                "    \"\"\"Calcula o retorno estimado de um investimento baseado no perfil de risco.\"\"\"\n",
                "    taxas = {\"baixo\": 0.10, \"medio\": 0.15, \"alto\": 0.25}\n",
                "    taxa = taxas.get(risco.lower(), 0.10)\n",
                "    \n",
                "    final = valor_inicial * ((1 + taxa) ** anos)\n",
                "    return f\"Investimento com risco {risco} após {anos} anos resultará em aproximadamente R$ {final:.2f}\"\n",
                "\n",
                "# 3. Criar a Ferramenta\n",
                "ferramenta_investimento = StructuredTool.from_function(\n",
                "    func=simular_investimento,\n",
                "    name=\"SimuladorInvestimentos\",\n",
                "    description=\"Útil para calcular projeções financeiras. Requer valor inicial, anos e perfil de risco.\",\n",
                "    args_schema=CalculadoraInvestimentoInput\n",
                ")\n",
                "\n",
                "tools = [ferramenta_investimento]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. O Impacto da Descrição no Prompt\n",
                "\n",
                "Vamos ver como o LLM \"enxerga\" essa ferramenta. É isso que o `create_react_agent` coloca no prompt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Nome: {ferramenta_investimento.name}\")\n",
                "print(f\"Descrição: {ferramenta_investimento.description}\")\n",
                "print(f\"Schema JSON:\\n{ferramenta_investimento.args}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Rodando com Agente Multi-Argumento\n",
                "\n",
                "Nota: O ReAct padrão do LangChain espera `Action Input` como uma STRING única. Para usar ferramentas multi-argumento com ReAct clássico, o agente precisa gerar um **JSON string** dentro do `Action Input`.\n",
                "\n",
                "Prompt Engineering Dica: Às vezes precisamos explicitar isso no prompt principal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import AgentExecutor, create_react_agent\n",
                "from langchain import hub\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
                "prompt = hub.pull(\"hwchase17/react\")\n",
                "\n",
                "agent = create_react_agent(llm, tools, prompt)\n",
                "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
                "\n",
                "query = \"Se eu investir 1000 reais por 5 anos num perfil de alto risco, quanto terei?\"\n",
                "\n",
                "try:\n",
                "    agent_executor.invoke({\"input\": query})\n",
                "except Exception as e:\n",
                "    print(f\"Erro esperado (às vezes): {e}\")\n",
                "    # O ReAct padrão às vezes luta para formatar múltiplos argumentos como string única.\n",
                "    # É aqui que entra o 'Structured Chat Agent' ou a melhoria do Prompt."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Prompt Engineering para Correção de Erros\n",
                "\n",
                "Quando definimos `handle_parsing_errors=True`, o LangChain usa um prompt interno para corrigir o agente quando ele falha. Podemos personalizar isso?\n",
                "\n",
                "Sim, passando uma string customizada ou função para `handle_parsing_errors`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def custom_error_handler(error) -> str:\n",
                "    return f\"\"\"ERRO DE FORMATAÇÃO ENCONTRADO NO SEU ULTIMO TURNO:\n",
                "    {error}\n",
                "    \n",
                "    LEMBRE-SE: Para usar 'SimuladorInvestimentos', o input deve ser UM JSON VÁLIDO.\n",
                "    Exemplo: Action Input: {{\"valor_inicial\": 100, \"anos\": 2, \"risco\": \"alto\"}}\n",
                "    Tente novamente corrigindo o formato.\"\"\"\n",
                "\n",
                "runner_robusto = AgentExecutor(\n",
                "    agent=agent, \n",
                "    tools=tools, \n",
                "    verbose=True, \n",
                "    handle_parsing_errors=custom_error_handler # Injeta isso no prompt se der erro\n",
                ")\n",
                "\n",
                "runner_robusto.invoke({\"input\": \"Invista 500 reais por 10 anos risco medio\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Conclusão dos 3 Notebooks\n",
                "\n",
                "1. **Fundamentos:** Vimos que agentes são apenas loops `while` com prompts inteligentes de `Thought/Action`.\n",
                "2. **LangChain:** Vimos como usar abstrações para escalar isso.\n",
                "3. **Avançado:** Viu que a \"inteligência\" muitas vezes reside na descrição precisa das ferramentas (docstrings) e nas mensagens de erro (correction prompts)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}